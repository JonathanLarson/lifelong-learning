{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble.forest import _generate_unsampled_indices\n",
    "from sklearn.ensemble.forest import _generate_sample_indices\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "import numpy as np\n",
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook investigates transfer learning (and, eventually, lifelong learning) using three methods: Ignoring possible useful information in disparate data sets, using the structure in learned trees to \"transfer\" information, and comparing two classifiers to assess how similar the underlying distributions are.\n",
    "\n",
    "In the two latter methods, the ideas underlying Guo's Conditional Entropy Forests are used to estimate posteriors.\n",
    "\n",
    "To see a full description of the task, see https://github.com/neurodata/lifelong-learning/blob/master/willy_nilly.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains code for conditional entropy forests. \n",
    "Adapted from https://github.com/rguo123/conditional_entropy_forests/blob/master/code/algorithm.py\n",
    "\"\"\"\n",
    "\n",
    "def finite_sample_correction(class_probs, row_sums):\n",
    "    \n",
    "    where_0 = np.argwhere(class_probs == 0)\n",
    "    for elem in where_0:\n",
    "        class_probs[elem[0], elem[1]] = 1 / (2 * row_sums[elem[0], None])\n",
    "    where_1 = np.argwhere(class_probs == 1)\n",
    "    for elem in where_1:\n",
    "        class_probs[elem[0], elem[1]] = 1 - 1 / (2 * row_sums[elem[0], None])\n",
    "    \n",
    "    return class_probs\n",
    "\n",
    "def build_model(X, y, n_estimators=200, max_samples=.32,\n",
    "                                            bootstrap=True,\n",
    "                                            depth=30,\n",
    "                                            min_samples_leaf=1):\n",
    "    if X.ndim == 1:\n",
    "        raise ValueError('1d data will cause headaches down the road')\n",
    "        \n",
    "    max_features = int(np.ceil(np.sqrt(X.shape[1])))\n",
    "        \n",
    "    model=BaggingClassifier(DecisionTreeClassifier(max_depth=depth, min_samples_leaf=min_samples_leaf,\n",
    "                                                     max_features = max_features),\n",
    "                              n_estimators=n_estimators,\n",
    "                              max_samples=max_samples,\n",
    "                              bootstrap=bootstrap)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def estimate_posteriors(model, train, y, test, in_task=True, acorn=None):\n",
    "    if acorn is None:\n",
    "        acorn = np.random.randint(10**6)\n",
    "    np.random.seed(acorn)\n",
    "    \n",
    "    n, d = train.shape\n",
    "    m, d_ = test.shape\n",
    "    \n",
    "    if d != d_:\n",
    "        raise ValueError(\"train and test data in different dimensions\")\n",
    "    \n",
    "    class_counts = np.zeros((m, model.n_classes_))\n",
    "    for tree in model:\n",
    "        # get out of bag indicies\n",
    "        if in_task:\n",
    "            prob_indices = _generate_unsampled_indices(tree.random_state, n)\n",
    "            # in_bag_idx = _generate_sample_indices(tree.random_state, n) # this is not behaving as i expected\n",
    "        else:\n",
    "            prob_indices = range(n)\n",
    "            in_bag_idx = range(n)\n",
    "        \n",
    "        all_leaf_nodes = tree.apply(train)\n",
    "        unique_leaf_nodes = np.unique(all_leaf_nodes)\n",
    "            \n",
    "        # get all node counts\n",
    "        node_counts = tree.tree_.n_node_samples\n",
    "        # get probs for eval samples\n",
    "        posterior_class_counts = np.zeros((len(unique_leaf_nodes), model.n_classes_))\n",
    "\n",
    "        for prob_index in prob_indices:\n",
    "            temp_node = tree.apply(train[prob_index].reshape(1, -1)).item()\n",
    "            posterior_class_counts[np.where(unique_leaf_nodes == temp_node)[0][0], y[prob_index]] += 1\n",
    "            \n",
    "        # total number of points in a node\n",
    "        row_sums = posterior_class_counts.sum(axis=1)\n",
    "        \n",
    "        # no divide by zero\n",
    "        row_sums[row_sums == 0] = 1\n",
    "\n",
    "        # posteriors\n",
    "        class_probs = (posterior_class_counts / row_sums[:, None])\n",
    "        # posteriors with finite sampling correction\n",
    "        \n",
    "        class_probs = finite_sample_correction(class_probs, row_sums)\n",
    "    \n",
    "        # posteriors as a list\n",
    "        class_probs.tolist()\n",
    "        partition_counts = np.asarray([node_counts[np.where(unique_leaf_nodes == x)[0][0]] for x in tree.apply(test)])\n",
    "        # get probability for out of bag samples\n",
    "        eval_class_probs = [class_probs[np.where(unique_leaf_nodes == x)[0][0]] for x in tree.apply(test)]\n",
    "        eval_class_probs = np.array(eval_class_probs)\n",
    "        # find total elements for out of bag samples\n",
    "        elems = np.multiply(eval_class_probs, partition_counts[:, np.newaxis])\n",
    "        # store counts for each x (repeat fhis for each tree)\n",
    "        class_counts += elems\n",
    "    # calculate p(y|X = x) for all x's\n",
    "    probs = class_counts / class_counts.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    return probs\n",
    "\n",
    "def predict(a):\n",
    "    return np.argmax(a, axis = 1)\n",
    "\n",
    "def permutation(predict1, predict2):\n",
    "    \"\"\"\n",
    "    how to use:\n",
    "    \n",
    "    this function returns the permutation i.e. \\pi: [K] -> [K] that maximizes\n",
    "    the number of matched predictions\n",
    "    \n",
    "    to use the permutation for posteriors for point i (posterior_i), say, simply use\n",
    "    posterior_i[permutation]\n",
    "    \n",
    "    \"\"\"\n",
    "    unique_1 = np.unique(predict1)\n",
    "    unique_2 = np.unique(predict2)\n",
    "    \n",
    "    if set(unique_1) != set(unique_2):\n",
    "        raise ValueError(\"predictions must be on the same set of labels\")\n",
    "        \n",
    "    K = len(unique_1)\n",
    "    \n",
    "    max_sum = 0\n",
    "    max_perm = unique_2\n",
    "    for i, perm in enumerate(permutations(unique_2)):\n",
    "        perm = np.array(list(perm))\n",
    "        temp_predict2 = -1*np.ones(len(predict2))\n",
    "        \n",
    "        for k in range(K):\n",
    "            temp_predict2[np.where(predict2 == unique_2[k])[0]] = perm[k]\n",
    "           \n",
    "        temp_sum = np.sum(predict1 == temp_predict2)\n",
    "        if temp_sum > max_sum:\n",
    "            max_sum = temp_sum\n",
    "            max_perm = perm\n",
    "            \n",
    "    return max_perm\n",
    "            \n",
    "def estimate_alpha(predict1, predict2, permutation=None):\n",
    "    if permutation is None:\n",
    "        return np.sum(predict1 == predict2) / len(predict1)\n",
    "    else:\n",
    "        unique = np.unique(temp_predict2)\n",
    "        temp_predict2 = -1*np.ones(len(predict2))\n",
    "        \n",
    "        for i, k in enumerate(unique):\n",
    "            temp_predict2[predict2 == k] = permutation[i]\n",
    "            \n",
    "        return np.sum(predict1 == temp_predict2) / len(predict1)\n",
    "    \n",
    "def generate_sample(n, pi, conditional_0, params0, conditional_1, params1, d = 2, acorn=None):\n",
    "    if acorn is None:\n",
    "        acorn = np.random.seed(10**6)\n",
    "    np.random.seed(acorn)\n",
    "    \n",
    "    n0 = int(np.random.binomial(n, pi))\n",
    "    n1 = n - n0\n",
    "    ns = [n0, n1]\n",
    "    \n",
    "    X0 = conditional_0(*params0, size=(n0, d))\n",
    "    \n",
    "    X1 = conditional_1(*params1, size=(n1, d))\n",
    "    \n",
    "    labels = np.concatenate([i*np.ones(ns[i]) for i in range(len(ns))]).astype(int)\n",
    "    \n",
    "    return [np.concatenate((X0, X1), axis = 0), labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [09:12<00:00, 137.87s/it]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "mc_its = 10 # number of simulation repititions\n",
    "# ns0 = (10*np.arange(3,5,step=1)).astype(int)\n",
    "ns1 = (100*np.arange(1, 3, step=0.5)).astype(int) # number of training samples \n",
    "# ns = np.concatenate((ns0, ns1))\n",
    "ns = ns1\n",
    "nz_prop = 1\n",
    "\n",
    "m = 100 # number of test samples each monte carlo iteration\n",
    "\n",
    "pi = 0.5\n",
    "cond_X_0, cond_X_1 = 2*[np.random.uniform]\n",
    "params_X_0, params_X_1 = [0, 0.5], [0.5, 1]\n",
    "\n",
    "cond_Z_0, cond_Z_1 = 2*[np.random.uniform]\n",
    "params_Z_0, params_Z_1 = [0.5, 1], [0, 0.5]\n",
    "\n",
    "algorithms = ['joint task1', 'joint task2', 'task1', 'task2', 'task1 cep global', 'task2 cep global', 'task1 jtv', 'task2 jtv']\n",
    "# algorithms = np.concatenate((algorithms, ['task1 cep local', 'task2 cep local', 'task1 jtv', 'task2 jtv']))\n",
    "M = len(algorithms)\n",
    "\n",
    "mean_error = np.zeros((len(algorithms), len(ns)))\n",
    "std_error = np.zeros((len(algorithms), len(ns)))\n",
    "\n",
    "d = 10\n",
    "for j, n in enumerate(tqdm(ns)):\n",
    "    errors = np.zeros((M, mc_its))\n",
    "    \n",
    "    k = int(np.floor(np.log(n)))\n",
    "    T = int(np.floor(np.sqrt(n)))\n",
    "    \n",
    "    for i in range(mc_its):\n",
    "        temp_predictions = [[] for __ in algorithms]\n",
    "        \n",
    "        X, labelsX = generate_sample(n, pi, cond_X_0, params_X_0, cond_X_1, params_X_1, d=d)\n",
    "        testX, test_labelsX = generate_sample(m, pi, cond_X_0, params_X_0, cond_X_1, params_X_1, d=d)\n",
    "        \n",
    "        Z, labelsZ = generate_sample(n, pi, cond_Z_0, params_Z_0, cond_Z_1, params_Z_1, d=d)\n",
    "        testZ, test_labelsZ = generate_sample(m, pi, cond_Z_0, params_Z_0, cond_Z_1, params_Z_1, d=d)\n",
    "        \n",
    "        joint, joint_labels = np.concatenate((X, Z)), np.concatenate((labelsX, labelsZ))\n",
    "        joint_test = np.concatenate((testX, testZ), axis = 0)\n",
    "        \n",
    "        model_joint = build_model(joint, joint_labels)\n",
    "        model_X = build_model(X, labelsX)\n",
    "        model_Z = build_model(Z, labelsZ)\n",
    "        \n",
    "        posteriors_structjoint_estjoint=estimate_posteriors(model_joint, joint, joint_labels, joint_test, in_task=True)\n",
    "        predictions_joint = predict(posteriors_structjoint_estjoint)\n",
    "        \n",
    "        # calculate errors for jointly learned forests\n",
    "        errors[0, i] = 1 - np.sum(test_labelsX == predictions_joint[range(m)])/m\n",
    "        errors[1, i] = 1 - np.sum(test_labelsZ == predictions_joint[range(m, 2*m)])/m\n",
    "        \n",
    "#         print(1 - np.sum(test_labelsX == predictions_joint[range(m)])/m, 1 - np.sum(test_labelsZ == predictions_joint[range(m, 2*m)])/m)\n",
    "        \n",
    "        posteriors_structX_estX=estimate_posteriors(model_X, X, labelsX, testX, in_task=True)\n",
    "        posteriors_structZ_estX=estimate_posteriors(model_Z, X, labelsX, testX, in_task=False)\n",
    "        \n",
    "        pred_structX_estX=predict(posteriors_structX_estX)\n",
    "        pred_structZ_estX=predict(posteriors_structZ_estX)\n",
    "        \n",
    "        posteriors_structX_estZ=estimate_posteriors(model_X, Z, labelsZ, testZ, in_task=False)\n",
    "        posteriors_structZ_estZ=estimate_posteriors(model_Z, Z, labelsZ, testZ, in_task=True)\n",
    "        \n",
    "        # calculate errors without attempting to transfer knowledge\n",
    "        pred_X = predict(posteriors_structX_estX)\n",
    "        pred_Z = predict(posteriors_structZ_estZ)\n",
    "        \n",
    "        errors[2, i] = 1 - np.sum(test_labelsX == pred_X)/m\n",
    "        errors[3, i] = 1 - np.sum(test_labelsZ == pred_Z)/m\n",
    "        \n",
    "        # cep global\n",
    "        pred_structX_estZ=predict(posteriors_structX_estZ)\n",
    "        pred_structZ_estZ=predict(posteriors_structZ_estZ)\n",
    "        \n",
    "        optimal_permutation_X = permutation(pred_structX_estX, pred_structZ_estX)\n",
    "        optimal_permutation_Z = permutation(pred_structZ_estZ, pred_structX_estZ)\n",
    "        \n",
    "        new_posteriors_structX_estZ = np.zeros(posteriors_structX_estZ.shape)\n",
    "        new_posteriors_structZ_estX = np.zeros(posteriors_structZ_estX.shape)\n",
    "        for k in range(m):\n",
    "            new_posteriors_structX_estZ[k] = posteriors_structX_estZ[k][optimal_permutation_X]\n",
    "            new_posteriors_structZ_estX[k] = posteriors_structZ_estX[k][optimal_permutation_Z]\n",
    "            \n",
    "        pred_structX_estZ = predict(posteriors_structX_estZ)\n",
    "        pred_structZ_estX = predict(posteriors_structZ_estX)\n",
    "        \n",
    "        alpha_X = estimate_alpha(pred_structX_estX, pred_structZ_estX)\n",
    "        alpha_Z = estimate_alpha(pred_structZ_estZ, pred_structX_estZ)\n",
    "            \n",
    "        pred_X_cep_global = predict(posteriors_structX_estX + alpha_X * new_posteriors_structZ_estX)\n",
    "        pred_Z_cep_global = predict(posteriors_structZ_estZ + alpha_Z * new_posteriors_structX_estZ)\n",
    "        \n",
    "        errors[4, i] = 1 - np.sum(test_labelsX == pred_X_cep_global)/m\n",
    "        errors[5, i] = 1 - np.sum(test_labelsZ == pred_Z_cep_global)/m\n",
    "        \n",
    "        # jtv ?\n",
    "        pred_X_jtv = predict(posteriors_structX_estX + posteriors_structZ_estX)\n",
    "        pred_Z_jtv = predict(posteriors_structZ_estZ + posteriors_structX_estZ)\n",
    "        \n",
    "        errors[6, i] = 1 - np.sum(test_labelsX == pred_X_jtv)/m\n",
    "        errors[7, i] = 1 - np.sum(test_labelsZ == pred_Z_jtv)/m\n",
    "    \n",
    "    mean_error[:, j] = np.mean(errors, axis=1)\n",
    "    std_error[:, j] = np.std(errors, ddof=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "algo_offset = 2\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for i, algo in enumerate(algorithms[algo_offset:]):\n",
    "    ax.plot(ns, mean_error[i + algo_offset], label=algo)\n",
    "ax.legend()\n",
    "ax.set_xlabel('n')\n",
    "ax.set_ylabel('L_hat')\n",
    "plt.savefig('uniform_10d.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
