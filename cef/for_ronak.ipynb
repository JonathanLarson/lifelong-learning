{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble.forest import _generate_unsampled_indices\n",
    "from sklearn.ensemble.forest import _generate_sample_indices\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LifelongForest:\n",
    "    \"\"\"\n",
    "    Lifelong Forest class.\n",
    "    \"\"\"\n",
    "    def __init__(self, acorn=None):\n",
    "        \"\"\"\n",
    "        Two major things the Forest Class needs access to:\n",
    "            1) the realized random forest model (self.models_ is a list of forests, 1 for each task)\n",
    "            2) old data (to update posteriors when a new task is introduced)\n",
    "        \"\"\"\n",
    "        self.models_ = []\n",
    "        self.X_ = []\n",
    "        self.y_ = []\n",
    "        self.n_tasks = 0\n",
    "        self.n_classes = None\n",
    "        \n",
    "        if acorn is not None:\n",
    "            np.random.seed(acorn)\n",
    "    \n",
    "    def new_forest(self, X, y, n_estimators=200, max_samples=0.32,\n",
    "                        bootstrap=True, max_depth=30, min_samples_leaf=1,\n",
    "                        acorn=None):\n",
    "        \"\"\"\n",
    "        Input\n",
    "        X: an array-like object of features; X.shape == (n_samples, n_features)\n",
    "        y: an array-like object of class labels; len(y) == n_samples\n",
    "        n_estimators: int; number of trees to construct (default = 200)\n",
    "        max_samples: float in (0, 1]: number of samples to consider when \n",
    "            constructing a new tree (default = 0.32)\n",
    "        bootstrap: bool; If True then the samples are sampled with replacement\n",
    "        max_depth: int; maximum depth of a tree\n",
    "        min_samples_leaf: int; minimum number of samples in a leaf node\n",
    "        \n",
    "        Return\n",
    "        model: a BaggingClassifier fit to X, y\n",
    "        \"\"\"\n",
    "        \n",
    "        if X.ndim == 1:\n",
    "            raise ValueError('1d data will cause headaches down the road')\n",
    "            \n",
    "        if acorn is not None:\n",
    "            np.random.seed(acorn)\n",
    "            \n",
    "        self.X_.append(X)\n",
    "        self.y_.append(y)\n",
    "            \n",
    "        n = X.shape[0]\n",
    "        K = len(np.unique(y))\n",
    "        \n",
    "        if self.n_classes is None:\n",
    "            self.n_classes = K\n",
    "        \n",
    "        max_features = int(np.ceil(np.sqrt(X.shape[1])))\n",
    "\n",
    "        model=BaggingClassifier(DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf,\n",
    "                                                         max_features = max_features),\n",
    "                                  n_estimators=n_estimators,\n",
    "                                  max_samples=max_samples,\n",
    "                                  bootstrap=bootstrap)\n",
    "\n",
    "        model.fit(X, y)\n",
    "        self.models_.append(model)\n",
    "        self.n_tasks += 1\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def _get_leaves(self, estimator):\n",
    "        \"\"\"\n",
    "        Internal function to get leaf node ids of estimator.\n",
    "        \n",
    "        Input\n",
    "        estimator: a fit DecisionTreeClassifier\n",
    "        \n",
    "        Return\n",
    "        leaf_ids: numpy array; an array of leaf node ids\n",
    "        \n",
    "        Usage\n",
    "        _estimate_posteriors(..)\n",
    "        \"\"\"\n",
    "        \n",
    "        # adapted from https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html\n",
    "        n_nodes = estimator.tree_.node_count\n",
    "        children_left = estimator.tree_.children_left\n",
    "        children_right = estimator.tree_.children_right\n",
    "        feature = estimator.tree_.feature\n",
    "        threshold = estimator.tree_.threshold\n",
    "\n",
    "        leaf_ids = []\n",
    "        stack = [(0, -1)] \n",
    "        while len(stack) > 0:\n",
    "            node_id, parent_depth = stack.pop()\n",
    "\n",
    "            # If we have a test node\n",
    "            if (children_left[node_id] != children_right[node_id]):\n",
    "                stack.append((children_left[node_id], parent_depth + 1))\n",
    "                stack.append((children_right[node_id], parent_depth + 1))\n",
    "            else:\n",
    "                leaf_ids.append(node_id)\n",
    "\n",
    "        return np.array(leaf_ids)\n",
    "    \n",
    "    \n",
    "    def _finite_sample_correction(self, class_probs, row_sums):\n",
    "        \"\"\"\n",
    "        An internal function for finite sample correction of posterior estimation.\n",
    "        \n",
    "        Input\n",
    "        class_probs: numpy array; array of posteriors to correct\n",
    "        row_sums: numpy array; array of partition counts\n",
    "        \n",
    "        Output\n",
    "        class_probs: numpy array; finite sample corrected posteriors\n",
    "        \n",
    "        Usage\n",
    "        _estimate_posteriors(..)\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        where_0 = np.argwhere(class_probs == 0)\n",
    "        for elem in where_0:\n",
    "            class_probs[elem[0], elem[1]] = 1 / (2 * row_sums[elem[0], None])\n",
    "        where_1 = np.argwhere(class_probs == 1)\n",
    "        for elem in where_1:\n",
    "            class_probs[elem[0], elem[1]] = 1 - 1 / (2 * row_sums[elem[0], None])\n",
    "    \n",
    "        return class_probs\n",
    "    \n",
    "    \n",
    "    def _estimate_posteriors(self, test, task_number, in_task=True, subsample=1, acorn=None):\n",
    "        \"\"\"\n",
    "        An internal function to estimate the posteriors.\n",
    "        \n",
    "        Input\n",
    "        task_number: int; indicates which model in self.model_ to use\n",
    "        test: array-like; test observation\n",
    "        in_task: bool; True if test is an in-task observation(s)\n",
    "        subsample: float in (0, 1]; proportion of out-of-task samples to use to\n",
    "            estimate posteriors\n",
    "            \n",
    "        Return\n",
    "        probs: numpy array; probs[i, k] is the probability of observation i\n",
    "            being class k\n",
    "            \n",
    "        Usage\n",
    "        predict(..)\n",
    "        \"\"\"\n",
    "        \n",
    "        if acorn is not None:\n",
    "            acorn = np.random.seed(acorn)\n",
    "            \n",
    "        train = self.X_[task_number]\n",
    "        y = self.y_[task_number]\n",
    "            \n",
    "        model = self.models_[task_number]\n",
    "\n",
    "        n, d = train.shape\n",
    "        \n",
    "        if test.ndim > 1:\n",
    "            m, d_ = test.shape\n",
    "        else:\n",
    "            m = len(test)\n",
    "            d_ = 1\n",
    "\n",
    "        class_counts = np.zeros((m, model.n_classes_))\n",
    "        for tree in model:\n",
    "            # get out of bag indicies\n",
    "            if in_task:\n",
    "                prob_indices = _generate_unsampled_indices(tree.random_state, n)\n",
    "                # in_bag_idx = _generate_sample_indices(tree.random_state, n) # this is not behaving as i expected\n",
    "            else:\n",
    "                prob_indices = np.random.choice(range(n), size=int(subsample*n), replace=False)\n",
    "\n",
    "            leaf_nodes = self._get_leaves(tree)\n",
    "            unique_leaf_nodes = np.unique(leaf_nodes)\n",
    "\n",
    "            # get all node counts\n",
    "            node_counts = tree.tree_.n_node_samples\n",
    "            # get probs for eval samples\n",
    "            posterior_class_counts = np.zeros((len(unique_leaf_nodes), model.n_classes_))\n",
    "\n",
    "            for prob_index in prob_indices:\n",
    "                temp_node = tree.apply(train[prob_index].reshape(1, -1)).item()\n",
    "                posterior_class_counts[np.where(unique_leaf_nodes == temp_node)[0][0], y[prob_index]] += 1\n",
    "\n",
    "            # total number of points in a node\n",
    "            row_sums = posterior_class_counts.sum(axis=1)\n",
    "\n",
    "            # no divide by zero\n",
    "            row_sums[row_sums == 0] = 1\n",
    "\n",
    "            # posteriors\n",
    "            class_probs = (posterior_class_counts / row_sums[:, None])\n",
    "            # posteriors with finite sampling correction\n",
    "\n",
    "            class_probs = self._finite_sample_correction(class_probs, row_sums)\n",
    "\n",
    "            # posteriors as a list\n",
    "            class_probs.tolist()\n",
    "\n",
    "            partition_counts = np.asarray([node_counts[np.where(unique_leaf_nodes == x)[0][0]] for x in tree.apply(test)])\n",
    "            # get probability for out of bag samples\n",
    "            eval_class_probs = [class_probs[np.where(unique_leaf_nodes == x)[0][0]] for x in tree.apply(test)]\n",
    "            eval_class_probs = np.array(eval_class_probs)\n",
    "            # find total elements for out of bag samples\n",
    "            elems = np.multiply(eval_class_probs, partition_counts[:, np.newaxis])\n",
    "            # store counts for each x (repeat fhis for each tree)\n",
    "            class_counts += elems\n",
    "        # calculate p(y|X = x) for all x's\n",
    "        probs = class_counts / class_counts.sum(axis=1, keepdims=True)\n",
    "\n",
    "        return probs\n",
    "\n",
    "\n",
    "    def predict(self, test, task_number=-1, subsample=1, single_task=False, acorn=None):\n",
    "        \"\"\"\n",
    "        Predicts the class labels for each sample in test.\n",
    "        \n",
    "        Input\n",
    "        test: array-like; either a 1d array of length n_features\n",
    "            or a 2d array of shape (m, n_features) \n",
    "        task_number: int; task number \"\"\"\n",
    "        sum_posteriors = np.zeros((test.shape[0], self.n_classes))\n",
    "        \n",
    "        if single_task:\n",
    "            sum_posteriors += self._estimate_posteriors(test,\n",
    "                                                        task_number,\n",
    "                                                        True,\n",
    "                                                        subsample,\n",
    "                                                        acorn)\n",
    "        else:\n",
    "            for i in range(self.n_tasks):\n",
    "                if task_number == i:\n",
    "                    sum_posteriors += self._estimate_posteriors(test,\n",
    "                                                                task_number,\n",
    "                                                                True,\n",
    "                                                                subsample,\n",
    "                                                                acorn)\n",
    "                else:\n",
    "                    sum_posteriors += self._estimate_posteriors(test,\n",
    "                                                                task_number,\n",
    "                                                                False,\n",
    "                                                                subsample,\n",
    "                                                                acorn)\n",
    "        return np.argmax(sum_posteriors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_rotation(theta=0, acorn=None):\n",
    "    if acorn is not None:\n",
    "        np.random.seed(acorn)\n",
    "    \n",
    "    R = np.array([\n",
    "        [np.cos(theta), np.sin(theta)],\n",
    "        [-np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "    \n",
    "    return R\n",
    "\n",
    "def generate_parity(n, d=2, theta=0, acorn=None):\n",
    "    if acorn is not None:\n",
    "        np.random.seed(acorn)\n",
    "        \n",
    "    X = np.random.uniform(-1, 1, size=(n, d))\n",
    "    Y = (np.sum(X > 0, axis=1) % 2 == 0).astype(int)\n",
    "    \n",
    "    if d == 2:\n",
    "        R = generate_2d_rotation()\n",
    "        X = X @ R\n",
    "    \n",
    "    return X, Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jovo_experiment(nx, nz, d, dist_x=generate_parity, dist_z=generate_parity, theta=0, m=100, subsample = 0.32, n_algos=6, return_posteriors = False):\n",
    "#     Tx = int(np.floor(np.sqrt(nx)))\n",
    "#     Tz = int(np.floor(np.sqrt(nz)))\n",
    "\n",
    "    Tx = 1\n",
    "    Tz = 1\n",
    "    \n",
    "    Kx = int(np.floor(np.log(nx)))\n",
    "    Kz = int(np.floor(np.log(nz)))\n",
    "    \n",
    "    errors = np.zeros(n_algos)\n",
    "\n",
    "    # Source task\n",
    "    X, labelsX = dist_x(nx, d)\n",
    "    testX, test_labelsX = dist_x(m, d)\n",
    "    \n",
    "    # Target task\n",
    "    Z, labelsZ = dist_z(nz, d)\n",
    "    testZ, test_labelsZ = dist_z(m, d)\n",
    "    \n",
    "    if len(X[0, :]) == 2:\n",
    "        R = generate_2d_rotation(theta)\n",
    "    else:\n",
    "        R = generate_3d_rotation()\n",
    "        \n",
    "    Z = Z @ R\n",
    "    testZ = testZ @ R\n",
    "\n",
    "    model_X = build_model(X, labelsX, Tx)\n",
    "    model_Z = build_model(Z, labelsZ, Tz)\n",
    "\n",
    "    posteriors_structX_estX=estimate_posteriors(model_X, X, labelsX, testX, in_task=True)\n",
    "    posteriors_structZ_estX=estimate_posteriors(model_Z, X, labelsX, testX, in_task=False, subsample=subsample)\n",
    "\n",
    "    pred_structX_estX=predict(posteriors_structX_estX)\n",
    "    pred_structZ_estX=predict(posteriors_structZ_estX)\n",
    "\n",
    "    posteriors_structX_estZ=estimate_posteriors(model_X, Z, labelsZ, testZ, in_task=False, subsample=subsample)\n",
    "    posteriors_structZ_estZ=estimate_posteriors(model_Z, Z, labelsZ, testZ, in_task=True)\n",
    "    \n",
    "    pred_structX_estZ=predict(posteriors_structX_estZ)\n",
    "    pred_structZ_estZ=predict(posteriors_structZ_estZ)\n",
    "\n",
    "    # calculate errors without attempting to transfer knowledge\n",
    "    pred_X = predict(posteriors_structX_estX)\n",
    "    pred_Z = predict(posteriors_structZ_estZ)\n",
    "\n",
    "    errors[0] = 1 - np.sum(test_labelsX == pred_X)/m\n",
    "    errors[3] = 1 - np.sum(test_labelsZ == pred_Z)/m\n",
    "    \n",
    "    errors[1] = 1 - np.sum(test_labelsX == pred_structZ_estX)/m\n",
    "    errors[4] = 1 - np.sum(test_labelsZ == pred_structX_estZ)/m\n",
    "\n",
    "    # jtv ?\n",
    "    pred_X_jtv = predict(posteriors_structX_estX + posteriors_structZ_estX)\n",
    "    pred_Z_jtv = predict(posteriors_structZ_estZ + posteriors_structX_estZ)\n",
    "\n",
    "    errors[2] = 1 - np.sum(test_labelsX == pred_X_jtv)/m\n",
    "    errors[5] = 1 - np.sum(test_labelsZ == pred_Z_jtv)/m\n",
    "    \n",
    "    if return_posteriors:\n",
    "        # returns posteriors for a fixed mesh..\n",
    "        mesh_ =np.array(list(itertools.product(np.arange(-4, 4+0.05, step=0.05), np.arange(-4, 4+0.05, step=0.05))))\n",
    "        \n",
    "        posteriors_structX_estX=estimate_posteriors(model_X, X, labelsX, mesh_, in_task=True)\n",
    "        posteriors_structZ_estX=estimate_posteriors(model_Z, X, labelsX, mesh_, in_task=False, subsample=subsample)\n",
    "\n",
    "        posteriors_structX_estZ=estimate_posteriors(model_X, Z, labelsZ, mesh_, in_task=False, subsample=subsample)\n",
    "        posteriors_structZ_estZ=estimate_posteriors(model_Z, Z, labelsZ, mesh_, in_task=True)\n",
    "                    \n",
    "        return posteriors_structX_estX, posteriors_structZ_estX, posteriors_structZ_estZ, posteriors_structX_estZ\n",
    "    else:\n",
    "        return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block runs parity experiments for exactly two tasks. \n",
    "# The experiments take a while, so i always run them on syntaptomes 1/2\n",
    "\n",
    "from tqdm import tqdm\n",
    "np.random.seed(1)\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "mc_its = 50 # number of simulation repititions\n",
    "ns = (100*np.arange(0.5, 4.5, step=0.5)).astype(int) # number of training samples \n",
    "\n",
    "m = 100 # number of test samples each monte carlo iteration\n",
    "\n",
    "algorithms = ['Decision Forest XOR', 'Decision Forest N-XOR', 'Lifelong Forests']\n",
    "algorithms = np.concatenate((algorithms, ['Decision Forest N-XOR', 'Decision Forest XOR', 'Lifelong Forests']))\n",
    "\n",
    "M = len(algorithms)\n",
    "\n",
    "mean_error = np.zeros((M, len(ns)))\n",
    "std_error = np.zeros((M, len(ns)))\n",
    "\n",
    "d = 2\n",
    "for j, n in enumerate(tqdm(ns)):\n",
    "    condensed_func = lambda x : jovo_experiment(100, x, d, theta=np.pi, m=m, n_algos=M)\n",
    "    \n",
    "    errors = np.array(Parallel(n_jobs=-2)(delayed(condensed_func)(int(x)) for x in n*np.ones(mc_its)))\n",
    "    \n",
    "    mean_error[:, j] = np.mean(errors, axis=0)\n",
    "    std_error[:, j] = np.std(errors, ddof=1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting cell.. \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "gs1 = gridspec.GridSpec(4, 4)\n",
    "sns.set()\n",
    "\n",
    "mc_it = mc_its\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "colors = sns.color_palette(\"Set1\", n_colors = M)\n",
    "    \n",
    "algo_offset=0\n",
    "names = ['rf', 'transfer', 'lifelong']\n",
    "for j, name in enumerate(names):\n",
    "    fig1 = plt.figure(figsize=(8,8))\n",
    "    ax3 = fig1.add_subplot(1,1,1)\n",
    "    for i, algo in enumerate(algorithms[:j+1]):\n",
    "        ax3.plot(ns, mean_error[i + algo_offset], label=algo, c=colors[i])\n",
    "        ax3.fill_between(ns, \n",
    "                mean_error[i + algo_offset] + 1.96*std_error[i + algo_offset]/np.sqrt(mc_it), \n",
    "                mean_error[i + algo_offset] - 1.96*std_error[i + algo_offset]/np.sqrt(mc_it), \n",
    "                where=mean_error[i + algo_offset] + 1.96*std_error[i + algo_offset]/np.sqrt(mc_it) >= mean_error[i + algo_offset] - 1.96*std_error[i + algo_offset]/np.sqrt(mc_it), \n",
    "                facecolor=colors[i], \n",
    "                alpha=0.15,\n",
    "                interpolate=True)\n",
    "    ax3.set_ylabel('Error (XOR)')\n",
    "    ax3.legend(loc='upper center', fontsize=15)\n",
    "    ax3.set_ylim(-0.01, 0.3)\n",
    "\n",
    "    fig1.subplots_adjust(wspace=0.1, hspace=0.15)\n",
    "\n",
    "    fig1.text(0.5, 0.04, 'N-XOR Sample Size', ha='center')\n",
    "#     plt.savefig('L2M_18mo_xor_nxor_%s.png'%(name))\n",
    "    \n",
    "algo_offset=3\n",
    "for j, name in enumerate(names):\n",
    "    fig1 = plt.figure(figsize=(8,8))\n",
    "\n",
    "    ax3 = fig1.add_subplot(1,1,1)\n",
    "    for i, algo in enumerate(algorithms[algo_offset:algo_offset+j+1]):\n",
    "        ax3.plot(ns, mean_error[i + algo_offset], label=algo, c=colors[i + algo_offset])\n",
    "        ax3.fill_between(ns, \n",
    "                mean_error[i + algo_offset] + 1.96*std_error[i + algo_offset]/np.sqrt(mc_it), \n",
    "                mean_error[i + algo_offset] - 1.96*std_error[i + algo_offset]/np.sqrt(mc_it), \n",
    "                where=mean_error[i + algo_offset] + 1.96*std_error[i + algo_offset]/np.sqrt(mc_it) >= mean_error[i + algo_offset] - 1.96*std_error[i + algo_offset]/np.sqrt(mc_it), \n",
    "                facecolor=colors[i +algo_offset], \n",
    "                alpha=0.15,\n",
    "                interpolate=True)\n",
    "    ax3.set_ylabel('Error (N-XOR)')\n",
    "    \n",
    "    ax3.legend(loc='upper center', fontsize=15)\n",
    "    ax3.set_ylim(-0.01, 0.3)\n",
    "\n",
    "    fig1.subplots_adjust(wspace=0.1, hspace=0.15)\n",
    "\n",
    "    fig1.text(0.5, 0.04, 'N-XOR Sample Size', ha='center')\n",
    "#     plt.savefig('L2M_18mo_nxor_xor_%s.png'%(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:12<21:25, 12.99s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:26<21:18, 13.05s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:39<21:06, 13.06s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:50<20:11, 12.62s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [01:04<20:16, 12.80s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [01:17<20:20, 12.99s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [01:30<20:10, 13.02s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [01:43<20:05, 13.10s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [01:57<20:00, 13.19s/it]\u001b[A\n",
      " 10%|█         | 10/100 [02:10<19:50, 13.23s/it]\u001b[A\n",
      " 11%|█         | 11/100 [02:23<19:34, 13.20s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [02:37<19:31, 13.31s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [02:50<19:12, 13.25s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [03:04<19:10, 13.38s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [03:17<18:54, 13.35s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [03:30<18:37, 13.30s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [03:44<18:28, 13.36s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [03:57<18:13, 13.34s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [04:11<18:08, 13.44s/it]\u001b[A\n",
      " 20%|██        | 20/100 [04:24<17:52, 13.41s/it]\u001b[A\n",
      " 21%|██        | 21/100 [04:37<17:39, 13.41s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [04:50<17:17, 13.30s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [05:03<16:59, 13.24s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [05:16<16:37, 13.13s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [05:29<16:26, 13.15s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [05:43<16:23, 13.29s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [05:57<16:27, 13.53s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [06:10<16:07, 13.43s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [06:24<15:48, 13.35s/it]\u001b[A\n",
      " 30%|███       | 30/100 [06:37<15:35, 13.37s/it]\u001b[A\n",
      " 31%|███       | 31/100 [06:51<15:28, 13.45s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [07:04<15:15, 13.47s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [07:18<15:03, 13.48s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [07:31<14:40, 13.34s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [07:44<14:29, 13.38s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [07:57<14:16, 13.38s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [08:11<14:00, 13.34s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [08:24<13:54, 13.46s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [08:38<13:36, 13.39s/it]\u001b[A\n",
      " 40%|████      | 40/100 [08:51<13:22, 13.38s/it]\u001b[A\n",
      " 41%|████      | 41/100 [09:05<13:15, 13.49s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [09:18<13:01, 13.48s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [09:32<12:48, 13.48s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [09:45<12:33, 13.45s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [09:58<12:18, 13.42s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [10:12<12:01, 13.36s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [10:25<11:49, 13.39s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [10:38<11:33, 13.34s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [10:52<11:20, 13.34s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [11:05<11:08, 13.38s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [11:19<10:54, 13.36s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [11:32<10:39, 13.32s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [11:45<10:27, 13.35s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [11:58<10:13, 13.33s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [12:12<10:01, 13.37s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [12:24<09:36, 13.10s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [12:37<09:20, 13.04s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [12:53<09:40, 13.82s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [13:07<09:33, 13.99s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [13:21<09:13, 13.84s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [13:35<09:07, 14.05s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [13:49<08:54, 14.06s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [14:04<08:44, 14.19s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [14:18<08:34, 14.29s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [14:33<08:20, 14.30s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [14:47<08:06, 14.30s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [15:01<07:50, 14.27s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [15:15<07:33, 14.17s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [15:29<07:19, 14.18s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [15:44<07:06, 14.22s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [15:59<06:58, 14.43s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [16:13<06:43, 14.41s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [16:27<06:28, 14.39s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [16:42<06:13, 14.35s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [16:56<05:58, 14.36s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [17:10<05:41, 14.25s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [17:24<05:26, 14.21s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [17:38<05:12, 14.20s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [17:53<04:59, 14.26s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [18:07<04:44, 14.22s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [18:21<04:29, 14.18s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [18:35<04:15, 14.22s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [18:49<04:01, 14.22s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [19:04<03:47, 14.21s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [19:18<03:34, 14.28s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [19:32<03:19, 14.26s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [19:46<03:04, 14.21s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [20:01<02:50, 14.25s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [20:14<02:35, 14.12s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [20:29<02:21, 14.11s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [20:42<02:05, 13.98s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [20:58<01:55, 14.38s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [21:13<01:42, 14.61s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [21:28<01:28, 14.73s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [21:43<01:13, 14.80s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [21:58<00:59, 14.88s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [22:13<00:44, 14.94s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [22:27<00:29, 14.81s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [22:42<00:14, 14.79s/it]\u001b[A\n",
      "100%|██████████| 100/100 [22:57<00:00, 14.90s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "# Stuff in action\n",
    "from tqdm import tqdm\n",
    "\n",
    "nmc=100 # n monte carlo iterations\n",
    "# ns=[75, 100, 125, 150, 200] # amount of data from each task \n",
    "ns = 5*[100]\n",
    "m=300 # amount of data from each task to estimate the risk\n",
    "d=2 # dimension of parity problem\n",
    "\n",
    "h=0.125\n",
    "fracs = np.arange(0, 0.5+h,step=h) \n",
    "thetas = np.pi*fracs\n",
    "n_tasks = len(thetas)\n",
    "\n",
    "accuracies = [np.zeros((nmc, len(thetas) - i)) for i in range(n_tasks)]\n",
    "STL_accuracies = [np.zeros((nmc, len(thetas) - i)) for i in range(n_tasks)]\n",
    "optimal_accuracies = np.zeros((nmc, len(thetas)))\n",
    "\n",
    "\n",
    "ratios = [np.zeros((nmc, len(thetas) - i)) for i in range(n_tasks)]\n",
    "optimal_ratios = np.zeros((nmc, len(thetas)))\n",
    "\n",
    "for _ in tqdm(range(nmc)):\n",
    "    L2F = LifelongForest()\n",
    "    for i, th in enumerate(thetas):\n",
    "        temp_X, temp_y = generate_parity(ns[i], d, th, acorn=_*i)\n",
    "        L2F.new_forest(temp_X, temp_y, n_estimators=int(np.sqrt(ns[i])))\n",
    "        \n",
    "        L2F_optimal = LifelongForest()\n",
    "        temp_X, temp_y = generate_parity(np.sum(ns), d, th, acorn=_*i)\n",
    "        L2F_optimal.new_forest(temp_X, temp_y, n_estimators=int(np.sqrt(np.sum(ns))))\n",
    "\n",
    "        for j in range(i+1):\n",
    "            test_X, test_y = generate_parity(m, d, thetas[j], acorn=_*i + j + 1)\n",
    "            predictions = L2F.predict(test_X, task_number=j)\n",
    "            accuracy = np.sum(predictions == test_y) / m\n",
    "            accuracies[j][_, i-j] = accuracy\n",
    "            STL_accuracies[j][_, i-j] = np.sum(L2F.predict(test_X, task_number=j, single_task=True) == test_y)/m\n",
    "            \n",
    "            if j == i:\n",
    "                optimal_accuracies[i] = np.sum(L2F_optimal.predict(test_X, task_number=0, single_task=True) == test_y)/m\n",
    "            \n",
    "            ratios[j][_, i-j] = (1 - accuracies[j][_, i-j]) / (1 - STL_accuracies[j][_, i-j])\n",
    "        optimal_ratios[i] = (1 - optimal_accuracies[i]) / (1 - STL_accuracies[j][_, i-j])\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-d62f400e4aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tasks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#     ax.plot(ns,(1 - np.array(mean_accuracies[i])), label = 'theta = %1.3f pi'%(fracs[i]), c=c[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_opt_ratios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'th=%1.2fpi'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfracs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#     ax.fill_between(np.arange(i+1, n_tasks+1),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/hh/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/hh/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/hh/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/hh/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# mean_accuracies = [1 - np.mean(accuracies[i],axis=0) for i in range(n_tasks)]\n",
    "# std_accuracies = [np.std(accuracies[i],ddof=1,axis=0) for i in range(n_tasks)]\n",
    "\n",
    "# STL_mean_accuracies = [1 - np.mean(STL_accuracies[i],axis=0) for i in range(n_tasks)]\n",
    "# STL_std_accuracies = [np.std(STL_accuracies[i],ddof=1,axis=0) for i in range(n_tasks)]\n",
    "\n",
    "mean_ratios = [np.mean(ratios[i],axis=0) for i in range(n_tasks)]\n",
    "std_ratios = [np.std(ratios[i],ddof=1,axis=0) for i in range(n_tasks)]\n",
    "\n",
    "mean_opt_ratios = [np.mean(optimal_ratios[i],axis=0) for i in range(n_tasks)]\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "c = sns.color_palette('Paired', n_colors=10)\n",
    "for i in range(n_tasks - 1):\n",
    "    ns = np.arange(i + 1, n_tasks + 1)\n",
    "#     ax.plot(ns,(1 - np.array(mean_accuracies[i])), label = 'theta = %1.3f pi'%(fracs[i]), c=c[i])\n",
    "    ax.plot(ns, mean_ratios[i], label = 'th=%1.2fpi'%(fracs[i]), c=c[i])\n",
    "    \n",
    "    ax.fill_between(np.arange(i+1, n_tasks+1), \n",
    "        mean_ratios[i] + 1.96*std_ratios[i]/np.sqrt(nmc), \n",
    "        mean_ratios[i] - 1.96*std_ratios[i]/np.sqrt(nmc), \n",
    "        where=mean_ratios[i] + 1.96*std_ratios[i]/np.sqrt(nmc) >= mean_ratios[i] - 1.96*std_ratios[i]/np.sqrt(nmc), \n",
    "        facecolor=c[i], \n",
    "        alpha=0.15,\n",
    "        interpolate=True)\n",
    "    \n",
    "    \n",
    "ax.scatter(n_tasks, mean_ratios[-1], c = c[9], label='th=%1.2fpi'%(fracs[-1]), s = 5)\n",
    "\n",
    "for i in range(n_tasks - 1):\n",
    "    ns = np.arange(i + 1, n_tasks + 1)\n",
    "#     ax.plot(ns,(1 - np.array(mean_accuracies[i])), label = 'theta = %1.3f pi'%(fracs[i]), c=c[i])\n",
    "    ax.plot(ns, mean_opt_ratios[i], label = 'th=%1.2fpi'%(fracs[i]), c=c[i])\n",
    "    \n",
    "#     ax.fill_between(np.arange(i+1, n_tasks+1), \n",
    "#         mean_ratios[i] + 1.96*std_ratios[i]/np.sqrt(nmc), \n",
    "#         mean_ratios[i] - 1.96*std_ratios[i]/np.sqrt(nmc), \n",
    "#         where=mean_ratios[i] + 1.96*std_ratios[i]/np.sqrt(nmc) >= mean_ratios[i] - 1.96*std_ratios[i]/np.sqrt(nmc), \n",
    "#         facecolor=c[i], \n",
    "#         alpha=0.15,\n",
    "#         interpolate=True)\n",
    "    \n",
    "    \n",
    "ax.scatter(n_tasks, mean_opt_ratios[-1], c = c[9], label='th=%1.2fpi'%(fracs[-1]), s = 5)\n",
    "\n",
    "\n",
    "    \n",
    "ax.set_title('Lifelong Learning Forests on R-XOR')\n",
    "ax.set_xlabel('Number of tasks seen')\n",
    "ax.set_ylabel('Transfer Efficiency')\n",
    "# ax.set_ylim(0.05 - 0.01, 0.5 + 0.01)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "# ax.set_yticks([1, 0.95, 0.90, 0.85, 0.80])\n",
    "ax.set_xticks(np.arange(1,n_tasks+1))\n",
    "ax.grid(axis='x')\n",
    "# plt.savefig('rxors_lifelong_equaln75_03112019.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hh",
   "language": "python",
   "name": "hh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
